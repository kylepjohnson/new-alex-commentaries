{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This notebook takes the training data in `pos_neg_instances` and outputs a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Union\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from internetarchive import search_items, get_item, Search\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from transformers import BertForTokenClassification, AdamW, BertTokenizer, BertTokenizerFast, BatchEncoding, TrainingArguments, Trainer\n",
    "\n",
    "from ner_pipeline.scrape_for_training import do_search, prepare_data, load_scraped_data, get_scraped_dataset_size\n",
    "from ner_pipeline.containers import TraingingBatch\n",
    "from ner_pipeline.dataset_ner import TrainingDataset\n",
    "from ner_pipeline.dataset_ner import TrainingExample\n",
    "from ner_pipeline.labelset import LabelSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly load the previously scraped pos/neg instances from saved text files.\n",
    "NUM_EXAMPLES: int = 10  # 10000\n",
    "POS_INSTANCES: list[dict[str, Union[str, dict[str, Union, str, int]]]] = \\\n",
    "    load_scraped_data(f\"pos_neg_instances/pos_instances_{NUM_EXAMPLES}.txt\")\n",
    "NEG_INSTANCES: list[dict[str, Union[str, dict[str, Union, str, int]]]] = \\\n",
    "    load_scraped_data(f\"pos_neg_instances/neg_instances_{NUM_EXAMPLES}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since did not find 10000 positive instances and 10000 negative instances, \n",
    "# we take 5000 each in this case.\n",
    "NUM_FOR_TRAINING: int = 10  # 5000\n",
    "LABELED_DATA: list[dict[str, Union[str, dict[str, Union, str, int]]]] = \\\n",
    "    POS_INSTANCES[:NUM_FOR_TRAINING] + NEG_INSTANCES[:NUM_FOR_TRAINING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LABELED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'I Megarians for Salamis, they quoted Iliad 2. 558, where ', 'annotations': [{'start': 37, 'end': 49, 'label': 'Citation'}]}, {'content': 'Megarians for Salamis, they quoted Iliad 2. 558, where ', 'annotations': [{'start': 35, 'end': 47, 'label': 'Citation'}]}, {'content': 'Megarians for Salamis, they quoted Iliad 2. 558, where ', 'annotations': [{'start': 35, 'end': 47, 'label': 'Citation'}]}]\n"
     ]
    }
   ],
   "source": [
    "print(LABELED_DATA[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: in future, consider shuffling pos/neg seperately\n",
    "random.shuffle(LABELED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE: int = len(LABELED_DATA)\n",
    "print(DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "DATASET_TRAIN: list[dict[str, Union[str, dict[str, Union, str, int]]]] = \\\n",
    "    LABELED_DATA[:DATASET_SIZE*17//20] # 85% training data\n",
    "DATASET_TRAIN_SIZE = len(DATASET_TRAIN)\n",
    "print(DATASET_TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances for training: 17\n",
      "Number of instances for testing: 3\n"
     ]
    }
   ],
   "source": [
    "DATASET_TEST = LABELED_DATA[DATASET_SIZE*17//20:] # 15% testing data\n",
    "DATASET_TEST_SIZE = len(DATASET_TEST)\n",
    "\n",
    "print(\"Number of instances for training: \" + str(DATASET_TRAIN_SIZE))\n",
    "print(\"Number of instances for testing: \" + str(DATASET_TEST_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save instances for training(train and eval) and testing\n",
    "TRAIN_FP: str = f\"labeled_data/train_{DATASET_TRAIN_SIZE}_of_{DATASET_SIZE}.pickle\"\n",
    "TEST_FP: str = f\"labeled_data/test_{DATASET_TEST_SIZE}_of_{DATASET_SIZE}.pickle\"\n",
    "\n",
    "with open(TRAIN_FP, \"wb\") as DATASET_TRAIN_FILE:\n",
    "    pickle.dump(DATASET_TRAIN, DATASET_TRAIN_FILE)\n",
    "\n",
    "with open(TEST_FP, \"wb\") as DATASET_TEST_FILE:\n",
    "    pickle.dump(DATASET_TEST, DATASET_TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickle file\n",
    "LOAD_TRAINING_PICKLES = False\n",
    "if LOAD_TRAINING_PICKLES:\n",
    "    with open(TRAIN_FP, \"rb\") as DATASET_MODEL_FILE:\n",
    "        DATASET_TRAIN = pickle.load(DATASET_MODEL_FILE)\n",
    "    with open(TEST_FP, \"rb\") as DATASET_MODEL_FILE:\n",
    "        DATASET_TEST = pickle.load(DATASET_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure BERT for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER: BertTokenizerFast = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_SET: LabelSet = LabelSet(labels=[\"Citation\"]) #Only one label in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# TODO: Understand why more results are returned than sent\n",
    "\n",
    "IL_OD_TRAINING_DATASET: TrainingDataset = TrainingDataset(\n",
    "    data=DATASET_TRAIN, tokenizer=TOKENIZER, label_set=LABEL_SET, tokens_per_batch=16\n",
    ")\n",
    "print(len(IL_OD_TRAINING_DATASET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingExample(input_ids=[117, 119, 119, 191, 132, 25550, 132, 178, 118, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], labels=[0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100])\n"
     ]
    }
   ],
   "source": [
    "print(IL_OD_TRAINING_DATASET[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset for train: 19\n",
      "Size of dataset for eval: 4\n"
     ]
    }
   ],
   "source": [
    "IL_OD_NER_TRAIN: list[TrainingExample] = IL_OD_TRAINING_DATASET[:len(IL_OD_TRAINING_DATASET)*17//20]\n",
    "IL_OD_NER_EVAL = IL_OD_TRAINING_DATASET[len(IL_OD_TRAINING_DATASET)*17//20:]\n",
    "print(\"Size of dataset for train: \" + str(len(IL_OD_NER_TRAIN)))\n",
    "print(\"Size of dataset for eval: \" + str(len(IL_OD_NER_EVAL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['O', 'B-Citation', 'I-Citation', 'L-Citation', 'U-Citation'])\n"
     ]
    }
   ],
   "source": [
    "# Get the label list\n",
    "print(IL_OD_TRAINING_DATASET.label_set.ids_to_label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL: BertForTokenClassification = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    num_labels=len(IL_OD_TRAINING_DATASET.label_set.ids_to_label.values())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_ARGS: TrainingArguments = TrainingArguments(\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER: Trainer = Trainer(\n",
    "    model=MODEL,\n",
    "    args=TRAINING_ARGS,\n",
    "    train_dataset=IL_OD_NER_TRAIN,\n",
    "    eval_dataset=IL_OD_NER_EVAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9, training_loss=0.8823407491048177, metrics={'train_runtime': 12.4709, 'train_samples_per_second': 4.571, 'train_steps_per_second': 0.722, 'total_flos': 589463128800.0, 'train_loss': 0.8823407491048177, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINER.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert_ner_il_od-with-gpu-10.model\n",
      "Configuration saved in bert_ner_il_od-with-gpu-10.model/config.json\n",
      "Model weights saved in bert_ner_il_od-with-gpu-10.model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "TRAINER.save_model(f\"bert_ner_il_od-with-gpu-{NUM_EXAMPLES}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
