{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import json\n",
    "import pickle\n",
    "from typing import Union\n",
    "\n",
    "from seqeval.metrics import accuracy_score, f1_score, classification_report, precision_score, recall_score\n",
    "from seqeval.scheme import BILOU\n",
    "from transformers import BertForTokenClassification, BertTokenizer, BertTokenizerFast, BatchEncoding\n",
    "from tokenizers import decoders, Encoding\n",
    "from torch import Tensor\n",
    "from ner_pipeline.labelset import LabelSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "NUM_EXAMPLES: int = 10  # 10000\n",
    "MODEL: BertForTokenClassification = BertForTokenClassification.from_pretrained(f\"bert_ner_il_od-with-gpu-{NUM_EXAMPLES}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_LIST: list[str] = ['O', 'B-Citation', 'I-Citation', 'L-Citation', 'U-Citation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER: BertTokenizerFast = BertTokenizerFast.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the labeled data for testing\n",
    "# this one works well: f\"labeled_data/test_1500_of_10000.pickle\"\n",
    "DATASET_TEST_SIZE: int = 1500\n",
    "DATASET_SIZE: int = 10000\n",
    "TEST_FP: str = f\"labeled_data/test_{DATASET_TEST_SIZE}_of_{DATASET_SIZE}.pickle\"\n",
    "with open(TEST_FP, \"rb\") as DATASET_TEST_FILE:\n",
    "    TEST_INSTANCES: list[dict[str, Union[str, dict[str, Union, str, int]]]] = \\\n",
    "        pickle.load(DATASET_TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'a blind man who appears at the feasts of Alcinous, and ', 'annotations': []}\n"
     ]
    }
   ],
   "source": [
    "print(TEST_INSTANCES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from out trained model\n",
    "PRED: list[list[str]] = list()\n",
    "for INSTANCE in TEST_INSTANCES:\n",
    "    INPUTS_LINE: Tensor = TOKENIZER.encode(INSTANCE[\"content\"], return_tensors=\"pt\")\n",
    "    # predict by the model\n",
    "    OUTPUTS_LINE: Tensor = MODEL(INPUTS_LINE).logits\n",
    "    PREDICTIONS_LINE: Tensor = torch.argmax(OUTPUTS_LINE, dim=2)\n",
    "    PRED_LINE_LABEL: list[str] = list()\n",
    "    for PREDICTION in PREDICTIONS_LINE[0].numpy():\n",
    "        PRED_LINE_LABEL.append(LABEL_LIST[PREDICTION])\n",
    "    PRED.append(PRED_LINE_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITATION_LABEL_SET: LabelSet = LabelSet(labels=[\"Citation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true results of citations to evaluate the performance of our model\n",
    "TRUE_INSTANCES: list[list[str]] = list()\n",
    "for INSTANCE in TEST_INSTANCES:\n",
    "    MATCH_TOKENIZED_BATCH: BatchEncoding = TOKENIZER(INSTANCE[\"content\"])\n",
    "    MATCH_TOKENIZED_TEXT: Encoding = MATCH_TOKENIZED_BATCH[0]\n",
    "    ALIGNED_LABEL_IDS: list[int] = CITATION_LABEL_SET.get_aligned_label_ids_from_annotations(\n",
    "        MATCH_TOKENIZED_TEXT, INSTANCE[\"annotations\"]\n",
    "    )\n",
    "    TRUE_LINE_LABEL: list[str] = list()\n",
    "    for MATCH_ID in ALIGNED_LABEL_IDS:\n",
    "        TRUE_LINE_LABEL.append(LABEL_LIST[MATCH_ID])\n",
    "    TRUE_INSTANCES.append(TRUE_LINE_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of predictions: 1500\n",
      "Length of truths: 1500\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of predictions: \" + str(len(PRED)))\n",
    "print(\"Length of truths: \" + str(len(TRUE_INSTANCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Citation       0.00      0.00      0.00       778\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       778\n",
      "   macro avg       0.00      0.00      0.00       778\n",
      "weighted avg       0.00      0.00      0.00       778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylejohnson/.pyenv/versions/3.9.5/envs/alex/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Precision and Recall result\n",
    "print(classification_report(TRUE_INSTANCES, PRED, mode='strict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
