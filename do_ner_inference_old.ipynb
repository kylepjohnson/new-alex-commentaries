{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ner_pipeline.prepare_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bt/7wsyzkls47lglb1kg__8y1p80000gn/T/ipykernel_5083/1539072798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mner_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malignment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malign_tokens_and_annotations_bilou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mner_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mner_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ner_pipeline.prepare_data'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from seqeval.metrics import accuracy_score, f1_score, classification_report, precision_score, recall_score\n",
    "from seqeval.scheme import BILOU\n",
    "from tokenizers import decoders, Encoding\n",
    "from transformers import BertForTokenClassification, BertTokenizer, BertTokenizerFast, BatchEncoding\n",
    "\n",
    "from ner_pipeline.alignment import align_tokens_and_annotations_bilou\n",
    "from ner_pipeline.prepare_data import prepare_data\n",
    "from ner_pipeline.labelset import LabelSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"BERT/bert_ner_finetuned_iliad-with-gpu-pattern2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-CLEntity', 'I-CLEntity', 'L-CLEntity', 'U-CLEntity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "odyssey_lines = []\n",
    "odyssey = open(\"example-texts/odyssey.txt\")\n",
    "for line in odyssey:\n",
    "    line = line.strip()\n",
    "    odyssey_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "odyssey_lines = [line for line in odyssey_lines if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The man for wisdom’s various arts renown’d,',\n",
       " 'Long exercised in woes, O Muse! resound;',\n",
       " 'Who, when his arms had wrought the destined fall',\n",
       " 'Of sacred Troy, and razed her heaven-built wall,',\n",
       " 'Wandering from clime to clime, observant stray’d,']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odyssey_lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man for wisdom’s various arts renown’d,\n",
      "['[CLS]', 'The', 'man', 'for', 'wisdom', '’', 's', 'various', 'arts', 're', '##no', '##wn', '’', 'd', ',', '[SEP]']\n",
      "tensor([[  101,  1109,  1299,  1111, 12304,   787,   188,  1672,  3959,  1231,\n",
      "          2728,  6540,   787,   173,   117,   102]])\n",
      "tensor([[[ 7.2442, -2.0015, -2.3737, -1.2922, -2.1233],\n",
      "         [ 4.1801, -0.7414, -2.4764, -1.9293,  0.3475],\n",
      "         [ 7.2216, -1.9274, -2.6654, -1.0237, -1.8203],\n",
      "         [ 7.7853, -2.3299, -2.5209, -1.0779, -2.8051],\n",
      "         [ 6.9263, -2.0333, -2.5033, -0.5697, -1.9279],\n",
      "         [ 8.0522, -2.4010, -2.2893, -1.0291, -2.8853],\n",
      "         [ 8.5481, -2.4405, -2.3758, -1.0778, -3.1764],\n",
      "         [ 8.4139, -2.4161, -2.6025, -1.2381, -2.7663],\n",
      "         [ 7.2092, -1.9773, -2.6219, -0.8822, -2.2727],\n",
      "         [ 8.8830, -2.3787, -2.5257, -1.5645, -3.1781],\n",
      "         [ 8.1743, -1.8957, -2.2802, -1.7129, -3.3336],\n",
      "         [ 8.5476, -2.6137, -2.5037, -1.1034, -3.0999],\n",
      "         [ 7.8153, -2.1804, -2.1192, -1.2381, -2.8452],\n",
      "         [ 7.6247, -2.1243, -2.2099, -1.1405, -2.9267],\n",
      "         [ 7.3531, -2.0150, -2.1520, -0.8633, -2.5242],\n",
      "         [ 6.9633, -1.5302, -3.0904, -1.4610, -1.0757]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for line in odyssey_lines:\n",
    "    tokens_line = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(line)))\n",
    "    inputs_line = tokenizer.encode(line, return_tensors=\"pt\")\n",
    "    print(inputs_line)\n",
    "    \n",
    "    outputs_line = model(inputs_line).logits\n",
    "    predictions_line = torch.argmax(outputs_line, dim=2)\n",
    "    print(predictions_line)\n",
    "    \n",
    "    pred_line_label = []\n",
    "    for prediction in predictions_line[0].numpy():\n",
    "        pred_line_label.append(label_list[prediction])\n",
    "    pred.append(pred_line_label)\n",
    "    print(pred_line_label)\n",
    "    break\n",
    "# with open('odyssey_ner_predictions.txt', 'w') as f:\n",
    "#     f.write(json.dumps(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('odyssey_ner_predictions.txt', 'r') as f:\n",
    "    pred = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "pattern = r'(\\b[A-Z][a-z]+\\b)(\\s\\b[A-Z][a-z]+\\b)*'\n",
    "odyssey_regex_matches = prepare_data(\"example-texts/odyssey.txt\", pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'The man for wisdom’s various arts renown’d,',\n",
       "  'annotations': [{'start': 0, 'end': 3, 'label': 'CLEntity'}]},\n",
       " {'content': 'Long exercised in woes, O Muse! resound;',\n",
       "  'annotations': [{'start': 0, 'end': 4, 'label': 'CLEntity'},\n",
       "   {'start': 26, 'end': 30, 'label': 'CLEntity'}]},\n",
       " {'content': 'Who, when his arms had wrought the destined fall',\n",
       "  'annotations': [{'start': 0, 'end': 3, 'label': 'CLEntity'}]},\n",
       " {'content': 'Of sacred Troy, and razed her heaven-built wall,',\n",
       "  'annotations': [{'start': 0, 'end': 2, 'label': 'CLEntity'},\n",
       "   {'start': 10, 'end': 14, 'label': 'CLEntity'}]},\n",
       " {'content': 'Wandering from clime to clime, observant stray’d,',\n",
       "  'annotations': [{'start': 0, 'end': 9, 'label': 'CLEntity'}]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odyssey_regex_matches[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clentity_label_set = LabelSet(labels=[\"CLEntity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "for match in odyssey_regex_matches:\n",
    "    \n",
    "    match_tokenized_batch : BatchEncoding = tokenizer(match[\"content\"])\n",
    "    match_tokenized_text : Encoding = match_tokenized_batch[0]\n",
    "    aligned_label_ids = clentity_label_set.get_aligned_label_ids_from_annotations(\n",
    "        match_tokenized_text, match[\"annotations\"]\n",
    "    )\n",
    "    match_tokens = match_tokenized_text.tokens\n",
    "    \n",
    "    true_line_label = []\n",
    "    for match_id in aligned_label_ids:\n",
    "        true_line_label.append(label_list[match_id])\n",
    "    true.append(true_line_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14409\n",
      "14409\n"
     ]
    }
   ],
   "source": [
    "print(len(true))\n",
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CLEntity       0.86      0.25      0.39     15928\n",
      "\n",
      "   micro avg       0.86      0.25      0.39     15928\n",
      "   macro avg       0.86      0.25      0.39     15928\n",
      "weighted avg       0.86      0.25      0.39     15928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true, pred, mode='strict', scheme=BILOU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
